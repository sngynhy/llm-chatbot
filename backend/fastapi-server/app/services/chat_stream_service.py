import time
from typing import AsyncGenerator
from openai import OpenAI
from app.config import settings

MODEL_NAME = "gemma:2b" # mistral, gemma:7b, wizard-math

class ChatStreamService:
    def __init__(self):
        self.client = OpenAI(base_url=settings.OLLAMA_BASE_URL, api_key=settings.OLLAMA_API_KEY)

    async def stream(self, question: str) -> AsyncGenerator[str, None]:
        print('stream', question)
        messages = [
            {"role": "system", "content": "ê°„ë‹¨íˆ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜."},
            {"role": "user", "content": question},
        ]

        # full_response = ""
        # response = None

        # try:
        #     # stream = self.client.chat.completions.create(
        #     #     model=MODEL_NAME,
        #     #     messages=messages,
        #     #     stream=True,
        #     # )

        #     # ë¹„ë™ê¸°ë¡œ OpenAI ìŠ¤íŠ¸ë¦¼ ìƒì„±
        #     response = await asyncio.get_event_loop().run_in_executor(
        #         None, 
        #         lambda: self.client.chat.completions.create(
        #             model=MODEL_NAME,
        #             messages=messages,
        #             stream=True,
        #             temperature=0.7,  # ì‘ë‹µ ë‹¤ì–‘ì„± ì¡°ì ˆ
        #             max_tokens=1000,  # ìµœëŒ€ í† í° ìˆ˜ ì œí•œ
        #         )
        #     )

        #     for chunk in response:
        #         # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ í™•ì¸
        #         if request and await self._is_client_disconnected(request):
        #             logging.info("í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€ ê°ì§€")
        #             break

        #         content = chunk.choices[0].delta.content or ""
        #         if not content:
        #             continue

        #         # ë¬¸ì¥ ë ê¸°í˜¸ë“¤ ê°ì§€í•˜ì—¬ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (ì , ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
        #         sentence_endings = ['.', '!', '?']
        #         if any(content.endswith(ending) for ending in sentence_endings):
        #             content += '\n'
        #         # print(content, end="", flush=True)
        #         full_response += content
        #         yield content.encode("utf-8")
        #         time.sleep(0.05)
        # except Exception as e:
        #     print(f"Error: {e}")
        #     return f"Error: {e}"
        # finally:
        #     print("ğŸ”Œ ì—°ê²° ì¢…ë£Œ", context["full_response"])
        #     # í˜„ì¬ ìš”ì²­ì˜ ìŠ¤íŠ¸ë¦¼ë§Œ ë‹«ìŒ (ì„¸ì…˜ì€ ì¬ì‚¬ìš©)
        #     try:
        #         stream.close()
        #     except Exception:
        #         pass